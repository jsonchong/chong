### 消息边界

RPC 需要在一条 TCP 链接上进行多次消息传递。在连续的两条消息之间必须有明确的分割规则，以便接收端可以将消息分割开来，这里的接收端可以是 RPC 服务器接收请求，也可以是 RPC 客户端接收响应。

基于 TCP 链接之上的单条消息如果过大，就会被网络协议栈拆分为多个数据包进行传送。如果消息过小，网络协议栈可能会将多个消息组合成一个数据包进行发送。对于接收端来说它看到的只是一串串的字节数组，如果没有明确的消息边界规则，接收端是无从知道这一串字节数组究竟是包含多条消息还是只是某条消息的一部分。

比较常用的两种分割方式是特殊分割符法和长度前缀法。

<img src="/Users/zhangchongchong/Library/Application Support/typora-user-images/image-20201118153913651.png" alt="image-20201118153913651" style="zoom:50%;" />

HTTP 和 Redis 协议就大量使用了`\r\n` 分割符。此种消息一般要求消息体的内容是文本消息。

基于特殊分割符法的优点在于消息的可读性比较强，可以直接看到消息的文本内容，缺点是不适合传递二进制消息，因为二进制的字节数组里面很容易就冒出连续的两个字节内容正好就是`\r\n` 分割符的 ascii 值。如果需要传递的话，一般是对二进制进行 base64 编码转变成普通文本消息再进行传送

### 消息的结构

每条消息都有它包含的语义结构信息，有些消息协议的结构信息是显式的，还有些是隐式的。比如 json 消息，它的结构就可以直接通过它的内容体现出来，所以它是一种显式结构的消息协议。

json 这种直观的消息协议的可读性非常棒，但是它的缺点也很明显，有太多的冗余信息。比如每个字符串都使用双引号来界定边界，key/value 之间必须有冒号分割，对象之间必须使用大括号分割等等。这些还只是冗余的小头，最大的冗余还在于连续的多条 json 消息即使结构完全一样，仅仅只是 value 的值不一样，也需要发送同样的 key 字符串信息。

消息的隐式结构一般是指那些结构信息由代码来约定的消息协议，在 RPC 交互的消息数据中只是纯粹的二进制数据，由代码来确定相应位置的二进制是属于哪个字段

### 消息压缩

如果消息的内容太大，就要考虑对消息进行压缩处理，这可以减轻网络带宽压力。但是这同时也会加重 CPU 的负担，因为压缩算法是 CPU 计算密集型操作，会导致操作系统的负载加重。所以，最终是否进行消息压缩，一定要根据业务情况加以权衡。

### 日志同步策略

```json
{
    "_track_id":992107155,
    "time":1605688815051,
    "type":"data_track",
    "distinct_id":"f77ca473bf81278f",
    "event":"INSERT",
    "properties":{
        "$os_version":"9",
        "$model":"MI 9",
        "$os":"Android",
        "$app_version":"1.0",
        "$device_id":"f77ca473bf81278f",
        "$app_name":"SensorsDataAPIDemo",
        "$log_version":"4.4.0",
        "$manufacturer":"Xiaomi",
        "$wifi":true,
        "value":[
            {
                "_id":"5325151341241",
                "table_name":"Record",
                "name":"购物",
                "money":"12000",
                "budget_id":"247323313",
                "remark":"好久没剁手了"
            }
        ],
        "$network_type":"WIFI"
    }
}
```



### 升级策略 

**情况一**

日志里新增了数据字段：对于老版本不会受新字段影响，对于新版本读取了老版本的日志数据，新增字段做缺省处理(根据log_version判断不一致就不读取新增字段)

### app记录日志流程

<img src="/Users/zhangchongchong/Library/Application Support/typora-user-images/image-20201118184620308.png" alt="image-20201118184620308" style="zoom:50%;" />



### 日志数据表结构

<img src="/Users/zhangchongchong/Library/Application Support/typora-user-images/image-20201118191328502.png" alt="image-20201118191328502" style="zoom:50%;" />



### 拉取数据流程

<img src="/Users/zhangchongchong/Library/Application Support/typora-user-images/image-20201119135958969.png" alt="image-20201119135958969" style="zoom:50%;" />



### 方案对比

#### 数据库文件同步方案：

**缺点**：

1. 多端数据同步问题，PC或者小程序如何同步构建数据
2. 增量更新问题，如何在后续做数据库文件的增量更新
3. 数据传输问题，随着数据库数据量增大，如何避免传输流量过大问题
4. 多端操作场景，同时修改，数据覆盖错误

**优点**：

1. 客户端业务代码不再需要关注数据同步的逻辑
2. 不依赖客户端时间
3. 可以在服务端直接修改数据库文件，校正客户端的错误

#### 打点模型行为日志方案：

**缺点**：

1. 客户端代码需要对每一步业务操作进行日志记录，并需要记录变更数据
2. 数据拉取增量同步时，需要根据hash值判断是否需要pull数据

**优点**：

1. 数据传输结构统一，通过json结构化的数据，无论数据的解析和序列化都是较为成熟的操作
2. 同步只做增量更新，传输流量可控，后续还可用rpc优化传输效率
3. 可不受客户端存储方式限制，如更换数据库系统，更换存储方式，以及跨端存储方式都不会受限制





```sqlite
select strftime('%Y-%m-%d',time/1000,'unixepoch', 'localtime') as days,
MAX(time) as maxCreateTime
from (select  revenue_time as time,
                  money as money
                   from revenue 
                   union 
                   select record_time as time,
                   money as money
                   from record ) group by strftime('%Y-%m-%d', time/1000, 'unixepoch', 'localtime') having strftime('%Y-%m', time/1000, 'unixepoch', 'localtime') = '2021-01'
```



```sqlite
select name, time ,remark,type from(select record_time as time,name,remark,type from record union
 select  revenue_time as time,name,remark,type from  revenue) 
 where strftime('%Y-%m', time/1000, 'unixepoch', 'localtime') = '2021-01' 
 order by time desc
```



```sqlite
CREATE INDEX Idx1 ON Record(record_time,name,remark,type);
```

```sqlite
CREATE INDEX Idx2 ON Revenue(revenue_time,name,remark,type);
```
















### 编译器全貌介绍

<img src="/Users/zhangchongchong/Library/Application Support/typora-user-images/image-20200907161026279.png" alt="image-20200907161026279" style="zoom:50%;" />

**三段式编译器的主要模块**：

- 第一段叫前端（Frontend）：其输入为源代码，输出为中间表示（Intermediate Representation，简写为IR，IR也被称作中间代码、中间语言）。IR没有标准语法。各编译器都可以自定义IR。比如LLVM就有LLVM IR，而Java字节码也是一种IR。前端的工作主要是解析输入的源码，并对其进行词法分析、语法分析、语义分析、生成对应的IR等。

- 第二段叫优化器（Optimizer）。**优化器的输入是未优化的IR，输出是优化后的IR**。常用的优化手段有循环优化、常量传播和折叠、无用代码消除、方法内联优化等。另外，优化器在优化阶段的最后还要执行一项非常重要的工作，即考虑如何分配物理寄存器。比如，IR中往往使用不限个数的虚拟寄存器，而目标机器的物理寄存器的个数却是有限的。所以优化器需要有一种方法来合理分配物理寄存器。而对那些不能保存在物理寄存器中的值，优化器还需要生成将这些值存储到内存、从内存中读取它们的指令。

- 最后一段叫后端（Backend）。其输入为优化后的IR，输出为目标机器的机器码。后端的主要功能是将IR翻译成机器码

  

  

<img src="/Users/zhangchongchong/Library/Application Support/typora-user-images/image-20200907171942516.png" alt="image-20200907171942516" style="zoom:50%;" />

优化器模块的输入是IR，输出也是IR。这种设计的好处是擅长优化的开发者可以将精力集中在如何优化IR上，而不会被输入的编程语言以及目标机器的特性所束缚



### 编译器前端介绍

首先是词法分析（Lexical Analysis），它将识别字符串中的单词，单词被称作Token，也叫标记。什么是Token呢？以编程语言为例，它包括关键字（比如if、for、int、long等）、标识符（变量名、函数名等）、运算符（+、-、*、/等）、常量（字符串常量、数值常量等）、界定符（Demiliter，如空格、分号、括号等有特殊含义的符号）等。显然，Token的定义和具体编程语言密切相关。另外，词法分析用到的技术说出来一点也不神秘，就是正则表达式。词法分析输出的是Token Stream（单词流，就是一连串的Token）

词法分析之后登场的就是语法分析（Syntax Analysis）。它将根据特定编程语言的文法规则对输入的Token流进行分析。文法规则也叫语法规则。比如，有着“主语谓语宾语”结构的句子是一个语法正确的句子，这就是一条语法规则。

语法正确的句子并不代表其语义也正确。比如，“人是植物”这句话符合“主语谓语宾语”的语法规则，但语义却不正确。所以编译器前端需要使用语义分析对源码进行检查，比如类型检查、语句相关性检查（比如case只能出现在switch语句里）、一致性检查（相同作用域内是否有重名变量）等。语义分析要综合代码的上下文信息，所以它也叫上下文相关分析（Context Sensitive Analysis）。

最后，编译器前端将生成源代码对应的IR。

**上文介绍了编译器前端的几个主要构成部分，从它们的实现方式来看：**

词法和语法分析可以手工编码（即编译器的实现者自己编写代码）或者用一些自动生成工具来生成相关代码，如下文要介绍的lex和yacc。

语义分析和IR难度较大，没有成熟通用的算法和自动生成工具，所以常常需要手工编码来实现。

### 词法分析和lex

词法分析的目标是识别输入字符流中的特定单词，**其用到的基础技术就是正则表达式**。在此，笔者拟直接介绍词法分析中的重要工具lex。

lex是Unix平台（包括Linux）上的一个工具程序，它能将输入的lex规则文件转换成对应的C代码。编译这个C代码就可得到一个能对输入的字符串按照指定规则（在输入的lex规则文件中指定）进行词法分析的可执行程序了。









